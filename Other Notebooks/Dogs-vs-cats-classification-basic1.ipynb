{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2334202,
     "status": "ok",
     "timestamp": 1554395313101,
     "user": {
      "displayName": "László Harri Németh",
      "photoUrl": "",
      "userId": "12415330340700821302"
     },
     "user_tz": -120
    },
    "id": "E8azhyJ6BNFz",
    "outputId": "fae1dce2-e1d1-4ca1-b910-2f848ac92047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training directory: /Users/harri/Programming/ml/dogs_vs_cats/train\n",
      "testing directory: /Users/harri/Programming/ml/dogs_vs_cats/test\n",
      "model loaded!\n",
      "2000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "#from google.colab import drive\n",
    "\n",
    "# for tensorboard log folder name\n",
    "from time import time\n",
    "\n",
    "# working with, mainly resizing, images\n",
    "import cv2                 \n",
    "\n",
    "# dealing with arrays\n",
    "import numpy as np         \n",
    "\n",
    "# dealing with directories\n",
    "import os                  \n",
    "\n",
    "# mixing up or currently ordered data that might lead our network astray in training.\n",
    "from random import shuffle \n",
    "\n",
    "# a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
    "from tqdm import tqdm      \n",
    "\n",
    "# neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# use PlaidML as backend for hardware acceleration\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "TRAIN = False\n",
    "FOLDER_PREFIX = '/Users/harri/Programming/ml/dogs_vs_cats'\n",
    "TRAIN_DIR = '{}{}'.format(FOLDER_PREFIX, '/train')\n",
    "print('training directory: {}'.format(TRAIN_DIR))\n",
    "TEST_DIR = '{}{}'.format(FOLDER_PREFIX, '/test')\n",
    "print('testing directory: {}'.format(TEST_DIR))\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "#LR = 1e-3\n",
    "\n",
    "# just so we remember which saved model is which, sizes must match\n",
    "MODEL_NAME = '{}{}'.format(FOLDER_PREFIX, '/dogs-vs-cats-{}.model'.format('2conv-basic1'))\n",
    "\n",
    "def label_img(imgname):\n",
    "    file_extension = imgname.split('.')[-1]\n",
    "    if file_extension != 'jpg': return 2\n",
    "    word_label = imgname.split('.')[-3]\n",
    "    if word_label == 'cat': return 0\n",
    "    elif word_label == 'dog': return 1\n",
    "\n",
    "    \n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    img = []\n",
    "    for imgname in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(imgname)\n",
    "        if label == 2:\n",
    "            continue\n",
    "        try:\n",
    "            path = os.path.join(TRAIN_DIR,imgname)\n",
    "            img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            training_data.append([np.array(img),np.array(label)])\n",
    "        except Exception as e:\n",
    "            print(\"error with image: '{}', exception: {}\".format(imgname, str(e)))\n",
    "    shuffle(training_data)\n",
    "    np.save('{}{}'.format(FOLDER_PREFIX, '/train_data_64_small.npy'), training_data)\n",
    "    return training_data\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    testing_data = []\n",
    "    for imgname in tqdm(os.listdir(TEST_DIR)):\n",
    "        try:\n",
    "            path = os.path.join(TEST_DIR,imgname)\n",
    "            img_num = imgname.split('.')[0]\n",
    "            img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            testing_data.append([np.array(img), img_num])\n",
    "        except Exception as e:\n",
    "            print(\"error with image: '{}', exception: {}\".format(imgname, str(e)))\n",
    "    shuffle(testing_data)\n",
    "    np.save('{}{}'.format(FOLDER_PREFIX, '/test_data_64_small.npy'), testing_data)\n",
    "    return testing_data\n",
    "\n",
    "\n",
    "# Check if training data file alrady exists\n",
    "train_data_exists = os.path.isfile('{}{}'.format(FOLDER_PREFIX, '/train_data_64_small.npy'))\n",
    "if train_data_exists:\n",
    "    # We have already created the dataset\n",
    "    train_data = np.load('{}{}'.format(FOLDER_PREFIX, '/train_data_64_small.npy'))\n",
    "else:\n",
    "    # Create the dataset\n",
    "    train_data = create_train_data()\n",
    "\n",
    "# Check if testing data file alrady exists\n",
    "test_data_exists = os.path.isfile('{}{}'.format(FOLDER_PREFIX, '/test_data_64_small.npy'))\n",
    "if test_data_exists:\n",
    "    # We have already created the dataset\n",
    "    test_data = np.load('{}{}'.format(FOLDER_PREFIX, '/test_data_64_small.npy'))\n",
    "else:\n",
    "    # Create the dataset\n",
    "    test_data = create_test_data()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation=tf.nn.relu, input_shape=(64, 64, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(512, (5, 5), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2,  activation=tf.nn.softmax)\n",
    "])\n",
    "    \n",
    "model.compile(optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "if os.path.exists(MODEL_NAME):\n",
    "    model.load_weights(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "shuffle(train_data)\n",
    "train = train_data[:2000]\n",
    "test = train_data[2000:2050]\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "\n",
    "if TRAIN == True:\n",
    "    \n",
    "    #tensorboard = tf.keras.callbacks.TensorBoard(log_dir='{}{}'.format(FOLDER_PREFIX, '/logs/{}'.format(time())))\n",
    "\n",
    "    model.fit(X,\n",
    "              Y,\n",
    "              epochs=4, \n",
    "              steps_per_epoch=500,\n",
    "              validation_data=(test_x,test_y),\n",
    "              validation_steps=50)\n",
    "              #validation_split=0.02,\n",
    "              #validation_steps=25,\n",
    "              #steps_per_epoch=num_train_examples,\n",
    "              #validation_data=(test_x, test_y),\n",
    "              #callbacks=[tensorboard])\n",
    "\n",
    "\n",
    "    model.save(MODEL_NAME)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 137ms/step - loss: 3.4401 - acc: 0.7400\n",
      "Accuracy on test dataset: 0.74\n"
     ]
    }
   ],
   "source": [
    "test = train_data[12345:12395]\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_x,test_y, steps=50)\n",
    "print('Accuracy on test dataset:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0cea68ff67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#plt.xlabel(class_names[label])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#i += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/ml/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/ml/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/Programming/ml/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/ml/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAPlJREFUeJzt3LFtwzAQQFExyAhKHe4/izRE6mQHZgTrBTBsI//VVxw+cCU51lpbrnl79AKvpFigWKBYoFigWKBYoFigWOBdhvd9X3POO63yOOd5/qy1Pm7NUaw553Ycx9+3elJjjK8rc50hKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWKBYoFigWGPJ/1hjje9u2S4+vX8znldf3FOu/6wxBsUCxQLFAsUCxQLFAsUCxwC/7Yho3gR+mYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "#i = 0\n",
    "image = test_x[0]\n",
    "print(image.shape)\n",
    "#for (image) in test_x.take(25):\n",
    "    #image = image.numpy().reshape((28,28))\n",
    "plt.subplot(1,1,1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(False)\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "#plt.xlabel(class_names[label])\n",
    "#i += 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Dogs-vs-cats-classification-basic1.ipynb",
   "provenance": [
    {
     "file_id": "1es90geJQjgeZHdHnWGwXC2uJi60eETfv",
     "timestamp": 1554277832574
    },
    {
     "file_id": "https://github.com/nlharri/udacity-tensorflow-free-course/blob/master/Other%20Notebooks/Dogs-vs-cats-classification.ipynb",
     "timestamp": 1554140948817
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
